<!-- title: Solving Problems Right -->

The world runs on things that work only well enough. The internet in my house works, most of the time. Management bonuses usually encourage productivity rather than infighting and zero-sum competition. Although correlation doesn’t imply causation, in practice it often does.

There are two big problems with systems that work well enough. The first is that, obviously, things can go badly wrong. Your network cuts out during a Zoom presentation. Your product managers focus on internal politics as your competitors overtake you. You think treatment A is more effective than treatment B, so you prescribe A. But really B is better; it’s just that people whose condition is less serious tend to choose A. The second, more insidious problem is that good-enough systems need constant oversight and upkeep. Are you responsible for the network outage, or is it your ISP? Is treatment A really better than treatment B? Are your product managers fighting? A good-enough world is a world of constant spontaneous combustion.

As a mathematician, I believe in well thought-out systems that are guaranteed correct (within limits). Academic researchers have developed many such systems; specialized programming languages like NetKAT for writing provably correct network protocols, “incentive compatible” mechanisms for motivating honest cooperation, and formal tools for learning cause and effect relationships (which I’ve been working on recently). These solutions could save millions of hours spent putting out fires, but because academics write for academics, they don’t see widespread use. I want to realize the transformative potential of these ideas.
